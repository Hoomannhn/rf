import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler


# --- 2. Clustering sur les valeurs brutes de 'shock' ---

# a) Extraire et standardiser les valeurs de 'shock'
X = df_filtre[['shock']].values  # On obtient un tableau 2D, nécessaire pour KMeans
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# b) Choix du nombre de clusters avec la méthode du coude et le silhouette score
distortions = []
sil_scores = []
K_range = range(2, 7)  # on teste de 2 à 6 clusters
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=0)
    kmeans.fit(X_scaled)
    labels = kmeans.labels_
    distortions.append(kmeans.inertia_)
    sil = silhouette_score(X_scaled, labels)
    sil_scores.append(sil)

# Tracé de la méthode du coude
plt.figure()
plt.plot(K_range, distortions, marker='o')
plt.xlabel('Nombre de clusters k')
plt.ylabel('Distortion (Inertie)')
plt.title("Méthode du coude sur les valeurs de 'shock'")
plt.show()

# Tracé du silhouette score
plt.figure()
plt.plot(K_range, sil_scores, marker='o')
plt.xlabel('Nombre de clusters k')
plt.ylabel('Silhouette Score')
plt.title("Silhouette Score sur les valeurs de 'shock'")
plt.show()

# Après observation des graphiques, choisissez le nombre de clusters (ici, par exemple, k=3)
k_opt = 3
kmeans_final = KMeans(n_clusters=k_opt, random_state=0)
df_filtre['shock_cluster'] = kmeans_final.fit_predict(X_scaled)

# --- 3. Analyser la répartition des clusters de chocs pour chaque rf_struct_id ---
clusters_par_struct = df_filtre.groupby('rf_struct_id')['shock_cluster'] \
    .agg(lambda x: x.value_counts().to_dict())

print("Répartition des clusters de chocs par rf_struct_id :")
print(clusters_par_struct)

# --- Optionnel : Visualisation ---
# Vous pouvez aussi visualiser la distribution des 'shock' colorée par leur label de cluster
plt.figure()
for cluster in range(k_opt):
    plt.scatter(
        df_filtre.loc[df_filtre['shock_cluster'] == cluster, 'rf_struct_id'],
        df_filtre.loc[df_filtre['shock_cluster'] == cluster, 'shock'],
        label=f'Cluster {cluster}'
    )
plt.xlabel('rf_struct_id')
plt.ylabel('shock')
plt.title("Distribution des chocs par rf_struct_id et clusters")
plt.legend()
plt.show()


********

# Création du DataFrame résultat
df_results = df_filtre[['rf_struct_id', 'shock_cluster', 'shock']].rename(columns={'shock_cluster': 'cluster'})

# Afficher le résultat
print(df_results.head())

**********
Voici un exemple complet qui réalise du clustering sur plusieurs features (par exemple, shock, une version numérique de pillars et un identifiant de scénario), puis qui projette ces données multi-dimensionnelles en 2D via la PCA et le t-SNE pour visualiser les clusters par couleur.

Dans cet exemple, on part du principe que votre DataFrame (ici appelé df_filtre) contient les colonnes suivantes :

rf_struct_id (identifiant)

pillars (ex. "1Y", "10Y", "6M", …)

shock (valeur numérique)

scenario_id (catégoriel ou numérique, optionnel)

Si vous n'avez pas la colonne scenario_id, le script utilisera seulement shock et pillars.



def convert_pillar_to_months(pillar):
    p = pillar.strip().upper()
    if 'Y' in p:
        # Ex : "1Y" -> 12, "10Y" -> 120
        return float(p.replace('Y', '')) * 12
    elif 'M' in p:
        # Ex : "6M" -> 6
        return float(p.replace('M',''))
    else:
        return np.nan

df_filtre['pillar_months'] = df_filtre['pillars'].apply(convert_pillar_to_months)

# --- Conversion de 'scenario_id' en variable numérique (si présente)
if 'scenario_id' in df_filtre.columns:
    # Si ce n'est pas déjà numérique, on convertit en code numérique
    if not np.issubdtype(df_filtre['scenario_id'].dtype, np.number):
        df_filtre['scenario_id_num'] = df_filtre['scenario_id'].astype('category').cat.codes
    else:
        df_filtre['scenario_id_num'] = df_filtre['scenario_id']
else:
    # Si la colonne n'existe pas, on n'utilisera que 'shock' et 'pillar_months'
    df_filtre['scenario_id_num'] = 0  # Remplit d'une valeur neutre

# --- Sélection des features pour le clustering
features = ['shock', 'pillar_months', 'scenario_id_num']

# On élimine les lignes avec des valeurs manquantes dans ces features
df_features = df_filtre.dropna(subset=features).copy()

X = df_features[features].values

# ----------------------------------------------------------------------------
# 2. Standardisation des features
# ----------------------------------------------------------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ----------------------------------------------------------------------------
# 3. Réalisation du clustering (ici K-Means)
# ----------------------------------------------------------------------------
# Choisissez le nombre de clusters (par exemple, k = 3, à ajuster selon vos analyses)
k_opt = 3
kmeans = KMeans(n_clusters=k_opt, random_state=0)
cluster_labels = kmeans.fit_predict(X_scaled)
df_features['cluster'] = cluster_labels

# ----------------------------------------------------------------------------
# 4. Réduction de dimension pour la visualisation
# ----------------------------------------------------------------------------

# Option A : Utilisation de la PCA
pca = PCA(n_components=2, random_state=0)
X_pca = pca.fit_transform(X_scaled)
df_features['PC1'] = X_pca[:, 0]
df_features['PC2'] = X_pca[:, 1]

plt.figure(figsize=(8, 6))
for c in sorted(df_features['cluster'].unique()):
    subset = df_features[df_features['cluster'] == c]
    plt.scatter(subset['PC1'], subset['PC2'], label=f'Cluster {c}', s=50)
plt.title("Clusters visualisés avec PCA")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.legend()
plt.show()

# Option B : Utilisation du t-SNE
# Attention : t-SNE est stochastique et peut demander quelques ajustements
tsne = TSNE(n_components=2, random_state=0, perplexity=30)
X_tsne = tsne.fit_transform(X_scaled)
df_features['tSNE1'] = X_tsne[:, 0]
df_features['tSNE2'] = X_tsne[:, 1]

plt.figure(figsize=(8, 6))
for c in sorted(df_features['cluster'].unique()):
    subset = df_features[df_features['cluster'] == c]
    plt.scatter(subset['tSNE1'], subset['tSNE2'], label=f'Cluster {c}', s=50)
plt.title("Clusters visualisés avec t-SNE")
plt.xlabel("tSNE1")
plt.ylabel("tSNE2")
plt.legend()
plt.show()


************

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler

# ----------------------------------------------------------------------------
# 1. Préparation et transformation des features
# ----------------------------------------------------------------------------
# On suppose que df_filtre est votre DataFrame existant avec les colonnes suivantes :
#    - 'rf_struct_id'
#    - 'pillars' (ex. "1Y", "10Y", "6M", "1D", "2W", etc.)
#    - 'shock'
#    - 'scenario_id' (optionnel)

# Exemple de données fictives (à remplacer par votre DataFrame réel) :
# data = {
#     'rf_struct_id': ['RISK_1', 'RISK_1', 'RISK_2', 'RISK_2', 'RISK_3', 'RISK_3'],
#     'pillars': ['1Y', '10Y', '6M', '2W', '1D', '10Y'],
#     'shock': [0.015, 0.007, -0.003, 0.002, 0.0001, -0.0005],
#     'scenario_id': ['A', 'A', 'B', 'B', 'A', 'C']
# }
# df_filtre = pd.DataFrame(data)

# --- Conversion de 'pillars' en une variable numérique en mois
def convert_pillar_to_months(pillar):
    p = pillar.strip().upper()
    # On va gérer les unités Années (Y), Mois (M), Semaines (W) et Jours (D)
    if 'Y' in p:
        # Exemple : "1Y" -> 1*12 = 12 mois, "10Y" -> 10*12 = 120 mois
        return float(p.replace('Y','')) * 12
    elif 'M' in p:
        # Exemple : "6M" -> 6 mois
        return float(p.replace('M',''))
    elif 'W' in p:
        # Conversion : 1 mois ≈ 4.33 semaines
        return float(p.replace('W','')) / 4.33
    elif 'D' in p:
        # Conversion : 1 mois ≈ 30 jours
        return float(p.replace('D','')) / 30.0
    else:
        return np.nan

df_filtre['pillar_months'] = df_filtre['pillars'].apply(convert_pillar_to_months)

# --- Conversion de 'scenario_id' en variable numérique (si la colonne existe)
if 'scenario_id' in df_filtre.columns:
    # Si la colonne n'est pas numérique, on la convertit en code numérique
    if not np.issubdtype(df_filtre['scenario_id'].dtype, np.number):
        df_filtre['scenario_id_num'] = df_filtre['scenario_id'].astype('category').cat.codes
    else:
        df_filtre['scenario_id_num'] = df_filtre['scenario_id']
else:
    # Si la colonne n'existe pas, on place une valeur neutre (ici, 0)
    df_filtre['scenario_id_num'] = 0

# --- Sélection des features pour le clustering
features = ['shock', 'pillar_months', 'scenario_id_num']

# On élimine les lignes avec des valeurs manquantes pour ces colonnes
df_features = df_filtre.dropna(subset=features).copy()

X = df_features[features].values

# ----------------------------------------------------------------------------
# 2. Standardisation des features
# ----------------------------------------------------------------------------
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ----------------------------------------------------------------------------
# 3. Réalisation du clustering (ici, K-Means)
# ----------------------------------------------------------------------------
# Ajustez k_opt (nombre de clusters) selon vos courbes du coude et du silhouette
k_opt = 3
kmeans = KMeans(n_clusters=k_opt, random_state=0)
cluster_labels = kmeans.fit_predict(X_scaled)
df_features['cluster'] = cluster_labels

# ----------------------------------------------------------------------------
# 4. Réduction de dimension pour la visualisation
# ----------------------------------------------------------------------------

# Option A : Projection via PCA en 2D
pca = PCA(n_components=2, random_state=0)
X_pca = pca.fit_transform(X_scaled)
df_features['PC1'] = X_pca[:, 0]
df_features['PC2'] = X_pca[:, 1]

plt.figure(figsize=(8, 6))
for c in sorted(df_features['cluster'].unique()):
    subset = df_features[df_features['cluster'] == c]
    plt.scatter(subset['PC1'], subset['PC2'], label=f'Cluster {c}', s=50)
plt.title("Visualisation des clusters avec PCA")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.legend()
plt.show()

# Option B : Projection via t-SNE en 2D
tsne = TSNE(n_components=2, random_state=0, perplexity=30)
X_tsne = tsne.fit_transform(X_scaled)
df_features['tSNE1'] = X_tsne[:, 0]
df_features['tSNE2'] = X_tsne[:, 1]

plt.figure(figsize=(8, 6))
for c in sorted(df_features['cluster'].unique()):
    subset = df_features[df_features['cluster'] == c]
    plt.scatter(subset['tSNE1'], subset['tSNE2'], label=f'Cluster {c}', s=50)
plt.title("Visualisation des clusters avec t-SNE")
plt.xlabel("tSNE1")
plt.ylabel("tSNE2")
plt.legend()
plt.show()

# ----------------------------------------------------------------------------
# 5. Création du DataFrame final
# ----------------------------------------------------------------------------
# On extrait uniquement les colonnes désirées : 'rf_struct_id', 'cluster' et 'shock'
df_results = df_features[['rf_struct_id', 'cluster', 'shock']].copy()

# Affichage du résultat (les 5 premières lignes, par exemple)
print(df_results.head())

************

# Pour calculer les statistiques sur "shock" par cluster dans df_results
stats_clusters = df_results.groupby('cluster')['shock'].agg(
    count='count',
    min='min',
    max='max',
    mean='mean'
).reset_index()

print(stats_clusters)
